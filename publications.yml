- title: "Improving SAM Requires Rethinking its Optimization Formulation"
  authors: Wanyun Xie, Fabian Latorre, Kimon Antonakopoulos, <b>Thomas Pethick</b>, Volkan Cevher
  conference: International Conference on Machine Learning (ICML) 2024
  paper: https://icml.cc/virtual/2024/poster/33271
  code: https://github.com/LIONS-EPFL/BiSAM.
  selected: true
- title: "Mixed Nash for Robust Federated Learning"
  authors: Wanyun Xie, <b>Thomas Pethick</b>, Ali Ramezani-Kebrya, Volkan Cevher
  conference: Transactions on Machine Learning Research (TMLR) 2024
  paper: https://openreview.net/pdf?id=mqMzerrVOB
- title: "Stable nonconvex-nonconcave training via linear interpolation"
  authors: <b>Thomas Pethick</b>, Wanyun Xie, Volkan Cevher
  conference: Neural Information Processing Systems (NeurIPS) 2023 <span style="color:red;">(spotlight)</span>
  paper: https://arxiv.org/pdf/2310.13459.pdf
  code: https://github.com/LIONS-EPFL/linear-interpolation
  selected: true
- title: "Solving stochastic weak Minty variational inequalities without increasing batch size"
  authors: <b>Thomas Pethick</b>, Olivier Fercoq, Puya Latafat, Panagiotis Patrinos and Volkan Cevher
  conference: International Conference on Learning Representations (ICLR) 2023
  paper: https://openreview.net/pdf?id=ejR4E1jaH9k
  code: https://github.com/LIONS-EPFL/stochastic-weak-minty-code
  selected: true
- title: "Federated Learning under Covariate Shifts with Generalization Guarantees"
  authors: Ali Ramezani-Kebrya, Fanghui Liu, <b>Thomas Pethick</b>, Grigorios Chrysos, Volkan Cevher
  conference: Transactions on Machine Learning Research (TMLR) 2023
  paper: https://arxiv.org/pdf/2306.05325.pdf
  code: https://github.com/LIONS-EPFL/Federated_Learning_Covariate_Shift_Code
- title: "Finding actual descent directions for adversarial training"
  authors: Fabian Latorre, Igor Krawczuk, Leello Tadesse Dadi, <b>Thomas Pethick</b> and Volkan Cevher
  conference: International Conference on Learning Representations (ICLR) 2023
  paper: https://openreview.net/pdf?id=I3HCE7Ro78H
  code: 
- title: "Revisiting adversarial training for the worst-performing class"
  authors: <b>Thomas Pethick</b> and Grigorios Chrysos and Volkan Cevher
  conference: Transactions on Machine Learning Research (TMLR) 2022
  paper: https://openreview.net/pdf?id=wkecshlYxI
  code: https://github.com/LIONS-EPFL/class-focused-online-learning-code
- title: "Escaping limit cycles: Global convergence for constrained nonconvex-nonconcave minimax problems"
  authors: <b>Thomas Pethick</b>, Puya Latafat, Panagiotis Patrinos, Olivier Fercoq, Volkan Cevher
  conference: The International Conference on Learning Representations (ICLR) 2022 <span style="color:red;">(spotlight)</span>
  paper: https://infoscience.epfl.ch/record/291889/files/escaping_limit_cycles_global_c.pdf
  code: https://github.com/LIONS-EPFL/weak-minty-code/
  selected: true
- title: "Sifting through the noise: Universal first-order methods for stochastic variational inequalities"
  authors:  Kimon Antonakopoulos, <b>Thomas Pethick</b>, Ali Kavis, Panayotis Mertikopoulos, Volkan Cevher
  conference: Neural Information Processing Systems (NeurIPS) 2021
  paper: https://infoscience.epfl.ch/record/289992/files/sifting_through_the_noise_univ-Supplementary%20Material.pdf
  code: https://github.com/LIONS-EPFL/vi-relative-noise-numerics
  selected: true
- title: "Subquadratic Overparameterization for Shallow Neural Networks"
  authors: Chaehwan Song, Ali Ramezani-Kebrya, <b>Thomas Pethick</b>, Armin Eftekhari, Volkan Cevher
  conference: Neural Information Processing Systems (NeurIPS) 2021
  paper: https://infoscience.epfl.ch/record/289650/files/OverpararXiv%281%29.pdf
  code: https://github.com/LIONS-EPFL/Subquadratic-Overparameterization
